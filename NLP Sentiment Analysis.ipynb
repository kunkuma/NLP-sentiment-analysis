{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd05cab",
   "metadata": {},
   "source": [
    "# 0. Pip Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b2625920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in c:\\users\\kunku\\anaconda3\\lib\\site-packages (0.1.22)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: kaggle in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from opendatasets) (1.5.16)\n",
      "Requirement already satisfied: click in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.5)\n",
      "Requirement already satisfied: requests in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.11)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2022.9.14)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (21.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from packaging->bleach->kaggle->opendatasets) (3.0.9)\n",
      "Requirement already satisfied: polars in c:\\users\\kunku\\anaconda3\\lib\\site-packages (0.19.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in c:\\users\\kunku\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wordcloud in c:\\users\\kunku\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from wordcloud) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kunku\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stop-words in c:\\users\\kunku\\anaconda3\\lib\\site-packages (2018.7.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install all requirements\n",
    "%pip install opendatasets\n",
    "%pip install polars\n",
    "%pip install nltk\n",
    "%pip install wordcloud\n",
    "%pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7554158",
   "metadata": {},
   "source": [
    "# 1. Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8de153ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\sentiment-analysis-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import polars as pl\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset\")\n",
    "file =('sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv')\n",
    "\n",
    "# Enter kaggle username and api key to download dataset. Api key can be found by following this link:\n",
    "# https://www.kaggle.com/settings/account\n",
    "\n",
    "df = pl.read_csv(file,separator=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "094e5578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (5, 6)\n┌─────────────┬─────────────────┬───────────────────┬──────────┬───────────────┬───────────────────┐\n│ polarity of ┆ id of the tweet ┆ date of the tweet ┆ query    ┆ user          ┆ text of the       │\n│ tweet       ┆ ---             ┆ ---               ┆ ---      ┆ ---           ┆ tweet             │\n│ ---         ┆ i64             ┆ str               ┆ str      ┆ str           ┆ ---               │\n│ i64         ┆                 ┆                   ┆          ┆               ┆ str               │\n╞═════════════╪═════════════════╪═══════════════════╪══════════╪═══════════════╪═══════════════════╡\n│ 0           ┆ 1467810672      ┆ Mon Apr 06        ┆ NO_QUERY ┆ scotthamilton ┆ is upset that he  │\n│             ┆                 ┆ 22:19:49 PDT 2009 ┆          ┆               ┆ can't update hi…  │\n│ 0           ┆ 1467810917      ┆ Mon Apr 06        ┆ NO_QUERY ┆ mattycus      ┆ @Kenichan I dived │\n│             ┆                 ┆ 22:19:53 PDT 2009 ┆          ┆               ┆ many times for…   │\n│ 0           ┆ 1467811184      ┆ Mon Apr 06        ┆ NO_QUERY ┆ ElleCTF       ┆ my whole body     │\n│             ┆                 ┆ 22:19:57 PDT 2009 ┆          ┆               ┆ feels itchy and   │\n│             ┆                 ┆                   ┆          ┆               ┆ li…               │\n│ 0           ┆ 1467811193      ┆ Mon Apr 06        ┆ NO_QUERY ┆ Karoli        ┆ @nationwideclass  │\n│             ┆                 ┆ 22:19:57 PDT 2009 ┆          ┆               ┆ no, it's not be…  │\n│ 0           ┆ 1467811372      ┆ Mon Apr 06        ┆ NO_QUERY ┆ joy_wolf      ┆ @Kwesidei not the │\n│             ┆                 ┆ 22:20:00 PDT 2009 ┆          ┆               ┆ whole crew        │\n└─────────────┴─────────────────┴───────────────────┴──────────┴───────────────┴───────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>polarity of tweet </th><th>id of the tweet</th><th>date of the tweet</th><th>query</th><th>user</th><th>text of the tweet </th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>1467810672</td><td>&quot;Mon Apr 06 22:…</td><td>&quot;NO_QUERY&quot;</td><td>&quot;scotthamilton&quot;</td><td>&quot;is upset that …</td></tr><tr><td>0</td><td>1467810917</td><td>&quot;Mon Apr 06 22:…</td><td>&quot;NO_QUERY&quot;</td><td>&quot;mattycus&quot;</td><td>&quot;@Kenichan I di…</td></tr><tr><td>0</td><td>1467811184</td><td>&quot;Mon Apr 06 22:…</td><td>&quot;NO_QUERY&quot;</td><td>&quot;ElleCTF&quot;</td><td>&quot;my whole body …</td></tr><tr><td>0</td><td>1467811193</td><td>&quot;Mon Apr 06 22:…</td><td>&quot;NO_QUERY&quot;</td><td>&quot;Karoli&quot;</td><td>&quot;@nationwidecla…</td></tr><tr><td>0</td><td>1467811372</td><td>&quot;Mon Apr 06 22:…</td><td>&quot;NO_QUERY&quot;</td><td>&quot;joy_wolf&quot;</td><td>&quot;@Kwesidei not …</td></tr></tbody></table></div>"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd82a11",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e16f0",
   "metadata": {},
   "source": [
    "## 2.1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "348a71bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (5, 2)\n┌───────────┬───────────────────────────────────┐\n│ sentiment ┆ text                              │\n│ ---       ┆ ---                               │\n│ str       ┆ str                               │\n╞═══════════╪═══════════════════════════════════╡\n│ negative  ┆ is upset that he can't update hi… │\n│ negative  ┆ @Kenichan I dived many times for… │\n│ negative  ┆ my whole body feels itchy and li… │\n│ negative  ┆ @nationwideclass no, it's not be… │\n│ negative  ┆ @Kwesidei not the whole crew      │\n└───────────┴───────────────────────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sentiment</th><th>text</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;negative&quot;</td><td>&quot;is upset that …</td></tr><tr><td>&quot;negative&quot;</td><td>&quot;@Kenichan I di…</td></tr><tr><td>&quot;negative&quot;</td><td>&quot;my whole body …</td></tr><tr><td>&quot;negative&quot;</td><td>&quot;@nationwidecla…</td></tr><tr><td>&quot;negative&quot;</td><td>&quot;@Kwesidei not …</td></tr></tbody></table></div>"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count()\n",
    "# No null data\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "# Drop columns that are not needed\n",
    "df = df.select(['sentiment', 'text'])\n",
    "\n",
    "# Convert polarity to sentiment\n",
    "# The polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "mapping = {0: 'negative', 2: 'neutral', 4: 'positive'}\n",
    "\n",
    "df = df.with_columns(pl.col('sentiment').map_dict(mapping).alias('sentiment'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec92584",
   "metadata": {},
   "source": [
    "## 2.2 Remove Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2b80da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df = df.with_columns(pl.col('text').map_elements(lambda x: re.sub(r\"http\\S+\",\"\", x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e9d16",
   "metadata": {},
   "source": [
    "## 2.3 Remove punctuations and special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d00a2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df = df.with_columns(pl.col('text').map_elements(lambda x: x.translate(str.maketrans('', '', string.punctuation))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902784bd",
   "metadata": {},
   "source": [
    "## 2.4 Lowercase all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9249c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.col('text').str.to_lowercase())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80899ed",
   "metadata": {},
   "source": [
    "## 2.5 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "086bf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.col('text')\n",
    "                     .str.split(by=\" \")\n",
    "                    .alias('tokenized_text'))\n",
    "cleaned_df = df.drop('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415a9ee",
   "metadata": {},
   "source": [
    "## 2.5 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e05513",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "stemmed_df = cleaned_df.with_columns(pl.col('tokenized_text').map_elements(lambda x: [stemmer.stem(word) for word in x if (word and word not in get_stop_words('english'))]).alias('stemmed_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575959e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stemmed_df = stemmed_df.drop('tokenized_text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2495c96",
   "metadata": {},
   "source": [
    "# 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e677f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stemmed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39fe381",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentiment_count =stemmed_df.select(pl.col('sentiment').value_counts(sort=True)).unnest('sentiment')\n",
    "plt.barh(y=sentiment_count['sentiment'], width=sentiment_count['counts'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This indicates more tweets with a negative sentiments than positive sentiments. No tweets could be found with a neutral sentiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Frequency of tokenized words\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def count_word_freq(column):\n",
    "    return Counter([item for sublist in column.to_list() for item in sublist])\n",
    "\n",
    "freq = count_word_freq(stemmed_df.get_column('stemmed_text'))\n",
    "freq_negative_sentiment = count_word_freq(stemmed_df.filter(pl.col('sentiment') == 'negative').get_column('stemmed_text'))\n",
    "freq_positive_sentiment = count_word_freq(stemmed_df.filter(pl.col('sentiment') == 'positive').get_column('stemmed_text'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize top 50 frequently used words\n",
    "word, frequency = zip(*freq.most_common(n=50))\n",
    "indices = np.arange(len(freq.most_common(n=50)))\n",
    "plt.bar(indices, frequency, color='b')\n",
    "plt.xticks(indices, word, rotation='vertical')\n",
    "plt.title('Top 50 frequently used words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create wordcloud\n",
    "import wordcloud\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "pos_cloud = wordcloud.WordCloud(max_words=150, random_state=30, collocations=True)\n",
    "neg_cloud = wordcloud.WordCloud(max_words=150, random_state=30, collocations=True)\n",
    "negative_sentiment_cloud = neg_cloud.generate_from_frequencies(dict(freq_negative_sentiment.most_common()))\n",
    "positive_sentiment_cloud = pos_cloud.generate_from_frequencies(dict(freq_positive_sentiment.most_common()))\n",
    "\n",
    "ax1.imshow(negative_sentiment_cloud, interpolation='bilinear')\n",
    "ax1.set_title('Negative Sentiment Words')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(positive_sentiment_cloud, interpolation='bilinear')\n",
    "ax2.set_title('Positive Sentiment Words')\n",
    "ax2.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15,15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Text Vectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import pickle as pk\n",
    "\n",
    "X = stemmed_df.select('stemmed_text')\n",
    "y = stemmed_df.select('sentiment')\n",
    "vector_size = 100\n",
    "\n",
    "fasttext_model = FastText(vector_size= vector_size, window= 3, min_count= 1, sg=1)\n",
    "fasttext_model.build_vocab(X.to_series())\n",
    "fasttext_model.train(X.to_series(), total_examples=fasttext_model.corpus_count, epochs=5)\n",
    "\n",
    "fasttext_model.save(\"fasttext/fasttext_model\")\n",
    "\n",
    "pk.dump(vector_size, open('word2vec/vector_size_w2v_metric.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
